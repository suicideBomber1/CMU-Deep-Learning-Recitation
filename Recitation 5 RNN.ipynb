{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data downloaded from https://www.kaggle.com/kingburrito666/better-donald-trump-tweets/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history_length = 3\n",
    "\n",
    "def process_input(filename):\n",
    "    text = open(filename).read()\n",
    "    sequences = [text[i:i+history_length] for i in range(int(len(text)/history_length))]\n",
    "    stats = Counter(sequences)\n",
    "    tokens = []\n",
    "    counts = []\n",
    "    for i in stats.most_common():\n",
    "        tokens.append(i[0])\n",
    "        counts.append(i[1])\n",
    "    return stats\n",
    "\n",
    "def next_char(cur, stats):\n",
    "    seed = cur[1:]\n",
    "    candidates = []\n",
    "    candidatec = []\n",
    "    for k in stats.keys():\n",
    "        if seed == k[:-1]:\n",
    "            candidates.append(k)\n",
    "            candidatec.append(stats[k])\n",
    "    candidatep = [x/sum(candidatec) for x in candidatec]\n",
    "    return candidates[np.random.choice(len(candidates), p=candidatep)]\n",
    "\n",
    "def sample(length, running_state, stats):\n",
    "    output = ''\n",
    "    for i in range(length):\n",
    "        output += running_state[0]\n",
    "        running_state = next_char(running_state, stats)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'obamil sh  dibizonlyised sed new govemit co zvknow'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_stats = process_input('tweets.txt')\n",
    "sample(50, 'oba', tweets_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'obamazing scrimes  afters any of the   ver  ters b'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_length = 4\n",
    "\n",
    "tweets_stats = process_input('tweets.txt')\n",
    "sample(50, 'obam', tweets_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and to say we end the mind that fles, and that fle'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamlet_stats = process_input('hamlet.txt')\n",
    "sample(50, 'and ', hamlet_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Above method just uses the history upto a certain number of characters to match the characters. But, there is no context of language generation, eventhough we increase the history length and also it is more memorization than text generation. \n",
    "> RNN's shine better in such cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
